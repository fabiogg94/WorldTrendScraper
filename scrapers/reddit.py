import requests
from datetime import datetime
from typing import List

from .schema import TrendItem
from .utils import save_trends_data, take_screenshot

# è¨­å®šè¦æŠ“å–çš„ Reddit URL åˆ—è¡¨
REDDIT_URLS = [
    {
        "url": "https://www.reddit.com/r/all/hot.json?limit=25",
        "filename": "reddit-all-hot.json",
        "description": "Reddit r/all ç†±é–€æ–‡ç« ",
    },
    {
        "url": "https://www.reddit.com/r/Taiwanese/hot.json?limit=25",
        "filename": "reddit-taiwanese-hot.json",
        "description": "Reddit r/Taiwanese ç†±é–€æ–‡ç« ",
    },
    {
        "url": "https://www.reddit.com/r/China_irl/hot.json?limit=25",
        "filename": "reddit-china-irl-hot.json",
        "description": "Reddit r/China_irl ç†±é–€æ–‡ç« ",
    },
]

BASE_URL = "https://www.reddit.com"

def fetch_reddit_trends():
    """ä½¿ç”¨ requests æŠ“å– Reddit JSON API ä¸¦è½‰æ›ç‚ºæ¨™æº–æ ¼å¼"""
    print("ğŸš€ é–‹å§‹æŠ“å– Reddit JSON è³‡æ–™...")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    for source in REDDIT_URLS:
        url = source["url"]
        filename = source["filename"]
        description = source["description"]

        try:
            print(f"\n--- è™•ç†: {description} ---")
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()

            raw_data = response.json()
            posts = raw_data.get('data', {}).get('children', [])
            
            trends: List[TrendItem] = []
            for post in posts:
                post_data = post.get('data', {})
                if not post_data:
                    continue

                # è™•ç†ç¸®åœ–ï¼Œå¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ http é€£çµå‰‡è¨­ç‚º None
                thumbnail = post_data.get('thumbnail')
                image_url = thumbnail if thumbnail and thumbnail.startswith('http') else None

                # å°‡ UTC æ™‚é–“æˆ³è½‰æ›ç‚º ISO æ ¼å¼
                timestamp = None
                if post_data.get('created_utc'):
                    timestamp = datetime.fromtimestamp(post_data['created_utc']).isoformat()

                trend_item: TrendItem = {
                    "title": post_data.get('title', 'N/A'),
                    "url": f"{BASE_URL}{post_data.get('permalink', '')}",
                    "score": str(post_data.get('score', 0)),
                    "image_url": image_url, # Will be updated below if needed
                    "timestamp": timestamp,
                }

                # If no image was found, take a screenshot
                if not trend_item["image_url"]:
                    trend_item["image_url"] = take_screenshot(trend_item["url"])
                
                trends.append(trend_item)

            # ä½¿ç”¨é€šç”¨çš„å„²å­˜å‡½å¼
            save_trends_data(filename, trends)

        except requests.RequestException as e:
            print(f"âŒ è™•ç† {description} æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤: {e}")
        except Exception as e:
            print(f"âŒ è™•ç† {description} æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")

    print("\nğŸ“Š Reddit æŠ“å–å®Œæˆ!")

if __name__ == '__main__':
    fetch_reddit_trends()

